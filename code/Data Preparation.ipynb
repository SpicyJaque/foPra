{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell contains the necessary imports and setups required for the project, including libraries for data manipulation, visualization, natural language processing, and API interaction. It also defines the file path and loads the DeepL API key for translation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Jacob\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Jacob\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jacob\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jacob\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Jacob\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from functions import *\n",
    "importlib.reload(functions)\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "file_path = \"C:/Users/Jacob/OneDrive/uni/MA WiSoz/Semester III/Computational Social Sciences/foPra/data/\"\n",
    "\n",
    "\n",
    "# Open the file in read mode\n",
    "with open(\"API Keys/DeepL.txt\", 'r', encoding='utf-8') as file:\n",
    "    # Read the contents of the file\n",
    "    api_key_deepl = file.read()\n",
    "\n",
    "url = 'https://api-free.deepl.com/v2/translate'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell initializes necessary variables, downloads required NLTK resources, and loads the DeepL API key for translation. It also sets up the API endpoint URL for DeepL and defines a list of political parties for further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit Text documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manifesto_raw = pd.read_csv(\"data/parties/All_Manifestos.csv\")\n",
    "df_manifesto_tokenized = pd.read_csv(\"data/parties/All_Manifestos_tokenized.csv\")\n",
    "cmp_categories = pd.read_csv(file_path  + \"cmp_categories.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell loads the manifesto data and related categories from CSV files into pandas DataFrames. It prepares the data for further processing by reading the manifesto text, tokenized text, and category mappings. The `file_path` variable is used to construct the path for the category file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to df_manifesto\n",
    "df_manifesto = process_manifesto_data(df_manifesto_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_manifesto with cmp_categories to add the description_md column\n",
    "df_manifesto = df_manifesto.merge(cmp_categories[['code', 'label', 'description_md']], \n",
    "                                  left_on='cmp_code', \n",
    "                                  right_on='code', \n",
    "                                  how='left')\n",
    "\n",
    "df_manifesto.rename(columns={\"label\": \"category\"}, inplace=True)\n",
    "\n",
    "# Drop the redundant 'code' column after the merge\n",
    "df_manifesto.drop(columns=['code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to df_manifesto to reduce noise\n",
    "df_manifesto = df_manifesto[ ~ ((df_manifesto['cmp_code'].isna()) & (df_manifesto['year'] > 1997))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manifesto.to_pickle('data\\df_manifesto.pkl')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
